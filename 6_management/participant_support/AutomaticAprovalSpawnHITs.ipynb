{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import xmltodict\n",
    "import json\n",
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_SECRET = os.environ['AWS_SECRET']\n",
    "AWS_REGION = os.environ['AWS_REGION']\n",
    "AWS_ACCESS_KEY = os.environ['AWS_ACCESS_KEY']\n",
    "DATA_COLLECTION_LOCATION=os.environ['DATA_COLLECTION_LOCATION']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_hits_in_live = False\n",
    "environments = {\n",
    "        \"live\": {\n",
    "            \"endpoint\": \"https://mturk-requester.us-east-1.amazonaws.com\",\n",
    "            \"preview\": \"https://www.mturk.com/mturk/preview\",\n",
    "            \"manage\": \"https://requester.mturk.com/mturk/manageHITs\",\n",
    "            \"reward\": \"0.00\"\n",
    "        },\n",
    "        \"sandbox\": {\n",
    "            \"endpoint\": \"https://mturk-requester-sandbox.us-east-1.amazonaws.com\",\n",
    "            \"preview\": \"https://workersandbox.mturk.com/mturk/preview\",\n",
    "            \"manage\": \"https://requestersandbox.mturk.com/mturk/manageHITs\",\n",
    "            \"reward\": \"0.11\"\n",
    "        },\n",
    "}\n",
    "mturk_environment = environments[\"live\"] if create_hits_in_live else environments[\"sandbox\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3 #.Session(profile_name='mturk')\n",
    "mturk = session.client(\n",
    "    service_name='mturk',\n",
    "    region_name=AWS_REGION,\n",
    "    aws_access_key_id = AWS_ACCESS_KEY, \n",
    "    aws_secret_access_key = AWS_SECRET,\n",
    "    endpoint_url=mturk_environment['endpoint'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"I have $\" + mturk.get_account_balance()['AvailableBalance'] + \" in my account\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create HITs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_template = open(\"templates/question_template.xml\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_layout = open('./templates/HIT2.html', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of using qualification to restrict responses to Workers who have had\n",
    "# at least 80% of their assignments approved. See:\n",
    "# http://docs.aws.amazon.com/AWSMechTurk/latest/AWSMturkAPI/ApiReference_QualificationRequirementDataStructureArticle.html#ApiReference_QualificationType-IDs\n",
    "participant_requirements = [{\n",
    "    'QualificationTypeId': '000000000000000000L0',\n",
    "    'Comparator': 'GreaterThanOrEqualTo',\n",
    "    'IntegerValues': [80],\n",
    "    'RequiredToPreview': True,\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hit(URL,challenge_response):\n",
    "    html_with_link=html_layout.replace('EXPERIMENTLINK',URL)\n",
    "    question_assembled=question_template.format(html_with_link)\n",
    "    # Create the HIT\n",
    "    response = mturk.create_hit(\n",
    "        MaxAssignments=1,\n",
    "        # How long the task will be available on MTurk \n",
    "        LifetimeInSeconds=600,\n",
    "        # How long Participants have to complete each item\n",
    "        AssignmentDurationInSeconds=600,\n",
    "        Reward=mturk_environment['reward'],\n",
    "        Title='This is a desktop Virtual Reality experiment',\n",
    "        Keywords='VR, slow, research',\n",
    "        Description='In this experiment you will slowly move through a building and will have to find specific targets.',\n",
    "        Question=question_assembled,\n",
    "        QualificationRequirements=participant_requirements,\n",
    "        AssignmentReviewPolicy={\n",
    "            'PolicyName':'ScoreMyKnownAnswers/2011-09-01',\n",
    "            'Parameters':[\n",
    "                {'Key':'AnswerKey', 'MapEntries':[\n",
    "                    {'Key': 'response_code', \n",
    "                     'Values':[challenge_response]\n",
    "                    }]},\n",
    "                {'Key': 'ApproveIfKnownAnswerScoreIsAtLeast', 'Values':['1']},\n",
    "                {'Key': 'RejectIfKnownAnswerScoreIsLessThan', 'Values':['1']},\n",
    "                {'Key': 'RejectReason', \n",
    "                 'Values':['Sorry, we could not approve your submission.']},\n",
    "                {'Key': 'ApproveReason', \n",
    "                 'Values':['Thank you for participating in the experiment!']},\n",
    "                {'Key': 'ExtendIfKnownAnswerScoreIsLessThan','Values':['1']}\n",
    "            ]\n",
    "        },\n",
    "    )\n",
    "    # The response included several fields that will be helpful later\n",
    "    hit_type_id = response['HIT']['HITTypeId']\n",
    "    hit_id = response['HIT']['HITId']\n",
    "    print(\"\\nCreated HIT: {} with response {}\".format(hit_id,challenge_response))\n",
    "    print(\"\\nYou can work the HIT here:\")\n",
    "    print(mturk_environment['preview'] + \"?groupId={}\".format(hit_type_id))\n",
    "    return hit_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../../experiment/data/AllCodesNew.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial=df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL=f\"{DATA_COLLECTION_LOCATION}/index.html?ExpID={trial['ExpID']}&group={trial['Condition']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_hit(URL,trial['exitCode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check HITs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hits=mturk.list_hits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in all_hits['HITs']:\n",
    "    print(h['HITId'])\n",
    "    print(h['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in all_hits['HITs']:\n",
    "    print(h['HITId'])\n",
    "    print(h['Title'])\n",
    "    HITId=h['HITId']\n",
    "    response = mturk.list_assignments_for_hit(\n",
    "        HITId=HITId,\n",
    "        MaxResults=100,\n",
    "        AssignmentStatuses=[\n",
    "            'Submitted','Approved','Rejected'\n",
    "        ]\n",
    "    )\n",
    "    try:\n",
    "        print (json.dumps(response, indent=2))\n",
    "    except:\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprove all assignments in HIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approveAllAssignments(hit_id):\n",
    "    # Get HIT status\n",
    "    status=mturk.get_hit(HITId=hit_id)['HIT']['HITStatus']\n",
    "    print('HITStatus:', status)\n",
    "    if status == 'Reviewable':\n",
    "        assignments = mturk.list_assignments_for_hit(HITId=hit_id, AssignmentStatuses=['Submitted'])\n",
    "        if assignments['NumResults'] > 0:\n",
    "            for assign in assignments['Assignments']:\n",
    "                mturk.approve_assignment(AssignmentId=assign['AssignmentId'])\n",
    "                print(\"Approved: \"+assign['AssignmentId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprove all assignments in all HITs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in mturk.list_hits()['HITs']:\n",
    "    hit_id=item['HITId']\n",
    "    approveAllAssignments(hit_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DANGER ZONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Force Delete HITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete HIT\n",
    "def deleteHit(hit_id):\n",
    "    # Get HIT status\n",
    "    status=mturk.get_hit(HITId=hit_id)['HIT']['HITStatus']\n",
    "    print('HITStatus:', status)\n",
    "\n",
    "    # If HIT is active then set it to expire immediately\n",
    "    if status=='Assignable' or status=='Unassignable':\n",
    "        print(\"Forcing it to expire\")\n",
    "        response = mturk.update_expiration_for_hit(\n",
    "            HITId=hit_id,\n",
    "            ExpireAt=datetime.datetime(2015, 1, 1)\n",
    "        )        \n",
    "    # Delete the HIT\n",
    "    try:\n",
    "        mturk.delete_hit(HITId=hit_id)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        print('Not deleted')\n",
    "    else:\n",
    "        print('Deleted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete All Hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in mturk.list_hits()['HITs']:\n",
    "    hit_id=item['HITId']\n",
    "    print('HITId:', hit_id)\n",
    "    deleteHit(hit_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in mturk.list_hits()['HITs']:\n",
    "    print(f\"HITId:{hit_id}\")\n",
    "    status=mturk.get_hit(HITId=item['HITId'])['HIT']['HITStatus']\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
